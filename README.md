# ğŸš€ QueryMyPDF â€” Chat with Your PDFs Locally (RAG + FAISS + Llama3)

QueryMyPDF is a **fully offline AI-powered document assistant**.

Upload PDFs â†’ Ask questions â†’ Get intelligent answers â€”  
**without cloud APIs, billing, or quotas.**

---

## ğŸ”¥ Powered By

- **Ollama (Llama3 Local LLM)**
- **LangChain**
- **FAISS Vector Store**
- **HuggingFace Embeddings (all-MiniLM-L6-v2)**
- **PDFPlumber for text extraction**
- **Streamlit UI**

ğŸ‘‰ Internet connection **not required**  
ğŸ‘‰ No API bills or tokens  
ğŸ‘‰ Runs entirely on your machine

---

---

## âœ¨ Features

âœ” Upload PDFs  
âœ” Extract text using PDFPlumber  
âœ” Local vector embeddings (MiniLM)  
âœ” RAG search over documents  
âœ” Query using **Llama3** via Ollama  
âœ” Shows document-referenced answers  

---

## ğŸ§± Architecture Overview

ğŸ“„ PDF â†’ ğŸ” Extract Text
â†“
ğŸ§© Chunking â†’ ğŸ“Œ Embedding â†’ ğŸ¯ FAISS Vector DB
â†“
ğŸ” Retrieval
â†“
ğŸ§  Local Llama3 â†’ generates response using context

---

## ğŸ›  Tech Stack

| Component      | Technology |
|----------------|------------|
| UI             | Streamlit |
| Embeddings     | HuggingFace Sentence Transformers |
| Vector DB      | FAISS |
| Model Runtime  | Ollama |
| Local LLM      | Llama3 |
| PDF Parsing    | pdfplumber |
| RAG Logic      | LangChain community components |

---

## ğŸ“‚ Project Structure

QueryMyPDF/
â”‚â”€â”€ app.py # Streamlit interface
â”‚â”€â”€ RAG_backend.py # Core RAG logic using Ollama
â”‚â”€â”€ requirements.txt # Dependencies
â”‚â”€â”€ README.md # Documentation
â””â”€â”€ venv (ignore)

---

## ğŸ“¸ Screenshots

### ğŸ“„ PDF Uploading Section
1.
  ![PDF Upload](assets/PDF_loader.png)
2.
  ![PDF Upload](assets/PDF_loader2.png)

### ğŸ¤– AI Response Output alongwith Source Doc
1.
  ![Source Docs](assets/source_doc.png),![Chat Answer](assets/response.png)
2.
  ![Source Docs](assets/source_doc1.png),![Chat Answer](assets/response1.png)


---


## ğŸ”§ Installation

1ï¸âƒ£ Clone repository

```bash
git clone https://github.com/chaudhary-pawan/QueryMyPDF.git
cd QueryMyPDF
```

2ï¸âƒ£ Install Ollama (REQUIRED)

ğŸ‘‰ Download from:

https://ollama.com/download

Then pull the model:

ollama pull llama3

3ï¸âƒ£ Create a virtual environment
python -m venv venv

4ï¸âƒ£ Install dependencies
pip install -r requirements.txt

â–¶ï¸ Run the app
streamlit run app.py

---

âœ” Upload PDFs
âœ” Ask questions
âœ” Get answers offline
